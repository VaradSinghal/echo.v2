<p align="center">
  <img src="public/echo_logo.svg" alt="Echo Agent Logo" width="120" />
</p>

<h1 align="center">ğŸŒŠ Echo Agent</h1>

<p align="center">
  <strong>Community-Driven Code Automation with AI Consensus</strong>
</p>

<p align="center">
  <a href="#-how-it-works">How It Works</a> â€¢
  <a href="#-features">Features</a> â€¢
  <a href="#-tech-stack">Tech Stack</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="USER_GUIDE.md">User Guide</a> â€¢
  <a href="#-contributing">Contributing</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Next.js-14-black?style=for-the-badge&logo=next.js" alt="Next.js 14" />
  <img src="https://img.shields.io/badge/Supabase-PostgreSQL-3ECF8E?style=for-the-badge&logo=supabase" alt="Supabase" />
  <img src="https://img.shields.io/badge/Qwen_2.5-Local_LLM-FF6F00?style=for-the-badge&logo=openai" alt="Local LLM" />
  <img src="https://img.shields.io/badge/pgVector-Embeddings-4169E1?style=for-the-badge&logo=postgresql" alt="pgVector" />
  <img src="https://img.shields.io/badge/Tailwind-CSS-38B2AC?style=for-the-badge&logo=tailwind-css" alt="Tailwind CSS" />
</p>

---

**Echo Agent** is an autonomous platform that bridges the gap between community sentiment and codebase evolution. It listens to your users wherever they speak â€” GitHub, Reddit, Product Hunt â€” analyzes their feedback using a **fully local LLM**, and automatically proposes code changes through Pull Requests. No cloud AI costs. No data leaving your machine.

---

## ğŸ§  How It Works

Echo Agent follows a closed-loop pipeline: **Listen â†’ Analyze â†’ Synthesize â†’ Act**.

```mermaid
graph LR
    A["ğŸ“¢ Community Feedback<br/>(Reddit, Product Hunt, GitHub)"] --> B["ğŸ” Scrapers<br/>(Puppeteer)"]
    B --> C["ğŸ§  Local LLM<br/>(Qwen 2.5 Coder 7B)"]
    C --> D["ğŸ“Š Sentiment & Priority<br/>Analysis"]
    D --> E["ğŸ”— Vector Embeddings<br/>(pgVector + MiniLM)"]
    E --> F{"âš–ï¸ Consensus<br/>Engine"}
    F -- "Actionable" --> G["ğŸ’» Code Generation<br/>(Local LLM)"]
    F -- "Noise" --> H["ğŸ—‘ï¸ Filtered"]
    G --> I["ğŸ”€ Pull Request<br/>(GitHub API)"]
    I --> J["ğŸ‘€ Human Review"]
```

| Step | What Happens |
|------|-------------|
| **1. Listen** | Scrapers pull comments from Reddit threads, Product Hunt pages, and GitHub discussions into Supabase. Real-time listeners auto-trigger on new data. |
| **2. Analyze** | The local **Qwen 2.5 Coder 7B** LLM classifies each comment: sentiment score (-1 to +1), category (bug / feature / question), priority, actionable summary, and keywords. |
| **3. Synthesize** | **Sentence-transformer embeddings** (all-MiniLM-L6-v2) are stored in pgVector. Semantic search clusters similar feedback to surface true community consensus. |
| **4. Act** | When the agent detects actionable feedback, it clones the target repo, generates code patches using the LLM, creates a branch, and opens a Pull Request â€” all automatically. |

---

## âœ¨ Features

### For Developers
| Feature | Description |
|---------|-------------|
| ğŸ¯ **Semantic Signal Detection** | Goes beyond keywords â€” identifies *intent*, *frustration levels*, and *priority* from raw feedback. |
| ğŸ¤– **Autonomous Code Agent** | Watches for high-priority signals, generates code patches, and opens PRs â€” zero manual intervention. |
| ğŸ’¬ **Multi-Platform Scrapers** | Ingest feedback from **Reddit**, **Product Hunt**, and GitHub with one click. |
| ğŸ” **Semantic Search** | Natural language queries like *"What are users complaining about in the login flow?"* powered by vector similarity. |
| ğŸ“ˆ **AI Insights Dashboard** | Real-time sentiment trends, community intelligence reports, and priority-ranked action items. |
| ğŸ–¥ï¸ **Live Agent Terminal** | Watch the AI agent work in real-time through a streaming terminal and execution trace view. |
| ğŸ›¡ï¸ **Human-in-the-Loop** | No code reaches production without your approval â€” every PR gets human review. |
| ğŸ”’ **100% Local Intelligence** | Powered entirely by Qwen 2.5 via `llama-cpp-python` â€” zero cloud LLM costs, zero data leaks. |

### For Businesses
| Feature | Description |
|---------|-------------|
| ğŸ“Š **Business Analytics Portal** | Track developer reach, community sentiment, and engagement metrics. |
| ğŸ” **Google OAuth Login** | Separate business login flow with Google, tailored for non-developer stakeholders. |
| ğŸ“‹ **Campaign & Sentiment Tracking** | Monitor developer sentiment across campaigns and product launches. |

### UI & Design
- **Brutalist Design Language** â€” Bold, high-contrast interface with thick borders, hard shadows, and uppercase typography.
- **Fully Responsive** â€” Works on desktop and mobile.
- **Dark Mode Login** â€” Dual-mode login page with developer (GitHub) and business (Google) toggles.

---

## ğŸ› ï¸ Tech Stack

### Architecture Overview

```mermaid
graph TB
    subgraph Frontend["Frontend (Next.js 14)"]
        LP[Landing Page]
        DA[Dashboard]
        BP[Business Portal]
        LG[Login / Auth]
    end

    subgraph Dashboard
        CF[Community Feed]
        AI[AI Insights]
        EA[Echo Agent]
        RD[Reddit Scraper]
        PH[Product Hunt Scraper]
        PR[Profile]
        SB[Subscription]
    end

    subgraph Backend["Python Backend (FastAPI)"]
        LLM["Qwen 2.5 Coder 7B<br/>(llama-cpp-python)"]
        EMB["Sentence Transformers<br/>(all-MiniLM-L6-v2)"]
        RL[Realtime Listener]
        CG[Code Generator]
    end

    subgraph Data["Data Layer"]
        SU[(Supabase / PostgreSQL)]
        PG["pgVector<br/>(384-dim embeddings)"]
        RD2["Upstash Redis<br/>(Rate Limiting)"]
    end

    subgraph External["External Services"]
        GH[GitHub API]
        PP[Puppeteer]
    end

    Frontend --> Backend
    Frontend --> Data
    Backend --> Data
    CG --> GH
    DA --> Dashboard
```

### Stack Details

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Framework** | Next.js 14 (App Router) | Server components, server actions, SSR |
| **Styling** | Tailwind CSS + Shadcn/ui + Radix UI | Brutalist component system |
| **Charts** | Recharts | Dashboard analytics visualizations |
| **Auth** | Supabase Auth (GitHub OAuth + Google OAuth) | Dual-mode authentication |
| **Database** | Supabase (PostgreSQL) | Posts, comments, profiles, agent tasks, tokens |
| **Vector Search** | pgVector (384-dim) | Semantic similarity search for feedback clustering |
| **Embeddings** | Sentence Transformers (all-MiniLM-L6-v2) | Local text-to-vector conversion |
| **LLM** | Qwen 2.5 Coder 7B Instruct (GGUF, Q5_K_M) | Comment analysis, report generation, code generation |
| **LLM Runtime** | llama-cpp-python | CPU/GPU inference for GGUF models |
| **Rate Limiting** | Upstash Redis | API rate limiting and throttling |
| **Scraping** | Puppeteer | Headless browser scraping for Reddit & Product Hunt |
| **Backend API** | FastAPI + Uvicorn | LLM inference, embedding generation, realtime processing |
| **VCS Integration** | GitHub REST API | Repo tree access, branch creation, PR automation |

---

## âš™ï¸ Quick Start

### Prerequisites

| Requirement | Version | Notes |
|-------------|---------|-------|
| **Node.js** | 18+ | Required for Next.js frontend |
| **Python** | 3.10+ | Required for FastAPI backend |
| **Supabase Account** | â€” | Free tier works. [Sign up here](https://supabase.com/) |
| **Upstash Redis** | â€” | Free tier works. [Sign up here](https://upstash.com/) |
| **GitHub OAuth App** | â€” | For developer login. [Create one here](https://github.com/settings/developers) |
| **Google OAuth** | â€” | For business login. [Google Cloud Console](https://console.cloud.google.com/) |
| **GPU (Optional)** | 6GB+ VRAM | Dramatically speeds up LLM inference |

### 1. Clone the Repository

```bash
git clone https://github.com/VaradSinghal/echo-v2.git
cd echo-v2
```

### 2. Install Frontend Dependencies

```bash
npm install
```

### 3. Configure Environment Variables

Create a `.env.local` file in the project root:

```env
# Supabase
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# Local Backend
LOCAL_EMBEDDING_URL=http://localhost:8000/embed

# Upstash Redis (Rate Limiting)
UPSTASH_REDIS_REST_URL=your_upstash_redis_url
UPSTASH_REDIS_REST_TOKEN=your_upstash_redis_token
```

Create a `.env` file inside `python_backend/`:

```env
SUPABASE_URL=your_supabase_project_url
SUPABASE_KEY=your_supabase_service_role_key
FRONTEND_URL=http://localhost:3000
```

### 4. Set Up the Database

Apply all migration files from `supabase/migrations/` to your Supabase project in order. These create the schema for:

| Table | Purpose |
|-------|---------|
| `profiles` | User profiles synced from OAuth |
| `github_tokens` | GitHub access tokens (per user) |
| `posts` | Scraped threads / topics |
| `comments` | Individual feedback entries |
| `comment_analysis` | LLM sentiment/priority analysis results |
| `agent_tasks` | Code generation task tracking |
| `comment_embeddings` | pgVector embeddings (384-dim) |

> [!TIP]
> You can paste each `.sql` file into the Supabase SQL Editor in your project dashboard, or use the Supabase CLI:
> ```bash
> supabase db push
> ```

### 5. Set Up the Python Backend

```bash
cd python_backend

# Create and activate a virtual environment
python -m venv venv
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 6. Download the LLM Model

```bash
python download_model.py
```

This downloads **Qwen 2.5 Coder 7B Instruct** (Q5_K_M quantization, ~5GB) from Hugging Face into the `python_backend/models/` directory.

> [!NOTE]
> First download may take 10-30 minutes depending on your connection. The model file is approximately 5GB.

### 7. Start the Backend

```bash
python main.py
```

The FastAPI server starts on `http://localhost:8000`. It will:
- Load the Qwen 2.5 model into memory
- Load the sentence-transformer embedding model
- Connect to Supabase and start listening for real-time events

### 8. Start the Frontend

Open a new terminal in the project root:

```bash
npm run dev
```

The Next.js app starts on `http://localhost:3000`.

---

## ğŸ“ Project Structure

```
echo-v2/
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ page.tsx                  # Landing page
â”‚   â”œâ”€â”€ login/                    # Dual-mode login (GitHub / Google)
â”‚   â”œâ”€â”€ auth/                     # OAuth callback handlers
â”‚   â”œâ”€â”€ dashboard/                # Protected dashboard routes
â”‚   â”‚   â”œâ”€â”€ feed/                 # Community feed viewer
â”‚   â”‚   â”œâ”€â”€ insights/             # AI-powered analytics
â”‚   â”‚   â”œâ”€â”€ agent/                # Echo Agent control center
â”‚   â”‚   â”œâ”€â”€ reddit/               # Reddit scraper interface
â”‚   â”‚   â”œâ”€â”€ product-hunt/         # Product Hunt scraper
â”‚   â”‚   â”œâ”€â”€ profile/              # User profile
â”‚   â”‚   â””â”€â”€ subscription/         # Plans & marketplace
â”‚   â”œâ”€â”€ business/                 # Business analytics portal
â”‚   â”œâ”€â”€ actions/                  # Server actions
â”‚   â”‚   â”œâ”€â”€ agent.ts              # Agent triggers, monitoring, search
â”‚   â”‚   â”œâ”€â”€ scraper.ts            # Reddit & PH scraping actions
â”‚   â”‚   â””â”€â”€ feed.ts               # Feed data actions
â”‚   â””â”€â”€ api/                      # API routes (GitHub callback, agent)
â”‚
â”œâ”€â”€ components/                   # React components
â”‚   â”œâ”€â”€ agent/                    # Agent terminal, monitoring, search
â”‚   â”œâ”€â”€ dashboard/                # Sidebar, local insights
â”‚   â”œâ”€â”€ landing/                  # Hero, features, nav, footer
â”‚   â”œâ”€â”€ feed/                     # Community feed components
â”‚   â”œâ”€â”€ reddit/                   # Reddit scraper UI
â”‚   â”œâ”€â”€ product-hunt/             # Product Hunt scraper UI
â”‚   â””â”€â”€ ui/                       # Shadcn/Radix primitives
â”‚
â”œâ”€â”€ lib/                          # Shared libraries
â”‚   â”œâ”€â”€ github.ts                 # GitHubService (tree, PR creation)
â”‚   â”œâ”€â”€ redis.ts                  # Upstash rate limiter
â”‚   â””â”€â”€ scraper/                  # Reddit & PH scraping logic
â”‚
â”œâ”€â”€ python_backend/               # FastAPI backend
â”‚   â”œâ”€â”€ main.py                   # API server + realtime listener
â”‚   â”œâ”€â”€ llm_service.py            # Qwen 2.5 LLM wrapper
â”‚   â”œâ”€â”€ download_model.py         # Model downloader script
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â””â”€â”€ models/                   # Downloaded GGUF models
â”‚
â”œâ”€â”€ supabase/
â”‚   â””â”€â”€ migrations/               # 16 SQL migration files
â”‚
â”œâ”€â”€ utils/                        # Supabase client utilities
â”‚   â””â”€â”€ supabase/                 # Server, client, middleware helpers
â”‚
â””â”€â”€ public/                       # Static assets (logos, SVGs)
```

---

## ğŸ”Œ API Endpoints (Python Backend)

The FastAPI backend exposes these endpoints on `http://localhost:8000`:

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check â€” confirms LLM and embeddings are loaded |
| `POST` | `/embed` | Generate 384-dim embedding for a text string |
| `POST` | `/analyze/{comment_id}` | Trigger sentiment analysis for a specific comment |
| `POST` | `/report` | Generate a community intelligence report from comment IDs |
| `POST` | `/top-comment` | Get the highest-priority comment from a set |
| `POST` | `/generate` | Clone a repo, generate code patches, and optionally create a PR |
| `POST` | `/reinitialize-llm` | Force-reload the LLM model |
| `GET` | `/logs` | Fetch the last 100 lines of backend logs |
| `POST` | `/v1/chat/completions` | OpenAI-compatible chat completions endpoint |

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork** the repository
2. **Create** your feature branch
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Commit** your changes
   ```bash
   git commit -m "feat: add amazing feature"
   ```
4. **Push** to your branch
   ```bash
   git push origin feature/amazing-feature
   ```
5. **Open** a Pull Request

### Development Tips

- Run `npm run lint` to check for linting errors
- The backend auto-reloads on file changes with `uvicorn --reload`
- Use the `/health` endpoint to verify the backend is running correctly

---

## ğŸ“„ License

Distributed under the **MIT License**. See `LICENSE` for more information.

---

<p align="center">
  <sub>Built with â¤ï¸ by <a href="https://github.com/VaradSinghal">Varad Singhal</a></sub>
</p>
